---
title: "HandoutI"
---

+-----------------------------------------+------------------+------------------+
| The Null Hypothesis is \_\_\_\_\_\_\_\_ | True             | False            |
+=========================================+==================+==================+
| **Rejected**                            | Type 1 Error     | Correct          |
|                                         |                  |                  |
|                                         | "False Positive" |                  |
+-----------------------------------------+------------------+------------------+
| **Not rejected**                        | Correct          | Type 2 error     |
|                                         |                  |                  |
|                                         |                  | "False Negative" |
+-----------------------------------------+------------------+------------------+

T1ER: Type 1 Error (is when you) Reject

T2EFTR: Type 2 Error (is when you) Fail To Reject

TYPE 1 ERROR: The null is true, you reject the null hypothesis

TYPE 2 ERROR: The alt is true, you fail to reject the null hypothesis

ALPHA: Probability of rejecting the null hypothesis when the null is true. For a p value standard of 0.05, alpha is 0.05\] ; AKA probability of type 1 error.

BETA: Probability of failing to reject the null hypothesis when the alt is true ; AKA, the probability of a type 2 error.

POWER: Likelihood of detecting an effect (rejecting the null hypothesis) if the alt is true. Power = 1-beta. AKA, probability of NOT making a type 2 error.

COMMON VARIANCE: The variance shared by two distributions when they have the same variance

The formula for power of two independent samples with equal variance requires a few variables:

-   significance level alpha

-   sample size

-   the sample type (e.g. two sample)

-   the effect size

We haven't seen the effect size, but we can calculate it with the following formula.

$$
effect size=\frac{|\mu_{1}-\mu_{2}|}{\sigma}
$$

$\mu_{1}=$ mean of your alternative distribution

$\mu_{2}=$ mean of your null distribution

$\sigma=$ common variance of the two distributions

To see the impact of the variables on the power level, the following charts were made by adjusting one of the variables and holding all other variables constant:

```{r}
numdf <- data.frame(
  inp <- seq(0,1, length=1000)
)

diff <- 10
sd <- sqrt(100)
effect <- diff/sd

numdf$yy <- (power.t.test(n=20, d = effect, sig.level = numdf$inp, power = NULL, type = "two.sample"))$power

plot(numdf$inp, numdf$yy,ylab="power",xlab="alpha", main="power as significance level alpha increases", )
```

```{r}
numdf <- data.frame(
  inp <- seq(0,200, length=1000)
)

diff <- 10
sd <- sqrt(100)
effect <- diff/sd

numdf$yy <- (power.t.test(n=numdf$inp, d = effect, sig.level = 0.05, power = NULL, type = "two.sample"))$power

plot(numdf$inp, numdf$yy,ylab="power",xlab="n", main="power as sample size increases", )
```

```{r}
numdf <- data.frame(
  inp <- seq(0,5, length=1000)
)

diff <- 10
sd <- sqrt(100)
effect <- diff/sd

numdf$yy <- (power.t.test(n=20, d = numdf$inp, sig.level = 0.05, power = NULL, type = "two.sample"))$power

plot(numdf$inp, numdf$yy,ylab="power",xlab="effect size", main="power as effect size increases", )
```
